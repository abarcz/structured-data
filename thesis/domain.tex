
\chapter{Domains of application\label{chap:domains}}
This chapter presents domains where data is organized into a structured form, that is form of sequences or graphs. The necessity of processing differently such kinds of data arose from the structure of the data itself. To present this difference we must first summarize what is the task of classification and regression in the most common meaning in the data processing domain. A common statistical classifier (which later on is called a \emph{vectorial} classifier) takes as input \emph{samples} from a given \emph{dataset}, representing real world objects, and associates each sample with a \emph{category}. The samples are fixed-length vectors of numeric values. Each position in such a vector represents a \emph{feature} of the sample, which is quantified by a real or integer value. The mapping from features to positions in the vector is fixed and must hold for each sample in the dataset. The category is represented by a non-empty fixed-length vector of integer values, where once again the position of each value is meaningful (we can say it's a \emph{positional} representation). For the regression task, a vector of real (or integer) values is associated with each sample instead of a category. The domain of vectorial classifiers is well developed and includes, among other solutions, neural networks, support vector machines, na√Øve Bayes classifiers and random forests.

In the case of graph processing, the nature of the data is different. Each \emph{sample} is represented by a \emph{graph}. A \emph{dataset} may consist of a single or several graphs. Each graph consists of nodes, connected with edges. Each node can be described by its \emph{label}, a fixed-length vector of reals. Each edge can also be labelled, with a fixed-length vector of reals of different size. Edges can be directed or undirected.

\begin{figure}
\begin{center}
	\includegraphics[scale=0.4]{img/tree}
	\caption{A simple binary tree}
	\label{fig:simple_tree}
\end{center}
\end{figure}

An example of a simple graph was presented in Fig.~\ref{fig:simple_tree}. If such a graph was to be used as input for a vectorial classifier, it would be necessary to transform the structured representation into a plain vector. It could be accomplished in several ways, one of the most obvious would be to perform a preorder walk on the tree and list the node labels in the order they were visited. Such a walk would result in the representation $[A,B,D,E,C]$. It can be seen that the explicit information about node adjacency was lost. Instead, the information is provided implicitly, according to a coding which must be known a priori to properly interpret such a vectorial representation. That means that a model learning to classify such graph representations would have to \emph{learn} the encoded relationship, instead of benefiting from it from the beginning to learn other, unknown and interesting relationships affecting the samples category. The resulting learning task becomes even harder if such sequential representations contain \emph{long-distance relationships}. Different encodings from structured data to vectors exist, however, they all share that flaw.

Moreover, the inadequacy of simple vector representation becomes even more apparent when the graph structure becomes more complicated. First of all, if edge labels are present in the vector representation, the representation becomes a mix of data belonging to two different entities - nodes and edges. Once again the classifier doesn't know which part of the data corresponds to the first entity and which to the other. The same applies to directed and undirected edges. If two edges in a graph are connected by a directed edge, presumably one of the nodes in the relation has got a larger impact on the other than vice versa. On the contrary, an undirected or bidirectional edge edge implies an equal impact of both nodes on each other. What if a graph contains both types of edges? How should one type of edges be distinguished from the other one? Secondly, let's consider the case of cyclic dependencies. Even if a meaningful representation of the graph is built ignoring cycles, e.g. by constructing a minimum spanning tree, some explicit information about connections is lost. An example of such data are chemical compounds containing groups of atoms forming cyclic bonds. Another problem lies in the positional nature of vectorial data. If a representation is built by simply storing node labels one after another, such a representation becomes vulnerable to any reordering of the children of a node. An additional effort must be made to assure a \emph{consistent ordering} of the potentially difficult to order data, while the ordering of the children of a node may be irrelevant in the dataset considered.

It can be seen that in order to properly process structured data, a different approach must be used. The data should be processed in a way that exploits properly the information contained in its structure - by means of building a sufficient representation or by processing the structured data directly. 

Graph-oriented models based on neural networks were successfully applied in various domains, including chemistry, pattern recognition and natural language processing. In the domain of computer-aided drug design the most important problem to solve is to predict the properties of a molecule prior to synthesizing it. All molecules with a negative prediction can be discarded automatically, reducing the costs of the subsequent laboratory experiments which can focus on the molecules with a positive prediction only~\cite{goulon2005hopfield}. This is the case of QSAR (quantitative structure-activity relations) and QSPR (quantitative structure-property relations). While traditional processing methods consist of extraction and selection of features from the molecules descriptions, the molecules can be easily represented as undirected graphs and processed with a graph-oriented model~\cite{goulon2007predicting}~\cite{goulon2005learning}.

The next domain of interest is document mining. As the amount of XML-formatted information increases rapidly, the problem of determining if a document can be assigned to a given category becomes crucial. As an XML document can be viewed as semi-structured data, graph-processing models can be successfully applied to this task~\cite{yong2006xml}. Another problem focused on document processing is the web page ranking, where documents and the links between them can be described as structured data. A general ranking model can be implemented as a graph-processing model, which allows exploiting page contents and link analysis simultaneously.~\cite{scarselli2005graph}~\cite{scarselli2009graph}.

In the domain of image processing two pattern recognition tasks can be distinguished. The first is the classification of images, either for industrial applications, control and monitoring, or for querying an image database. The second is object localisation, which may be used e.g. for face localisation. For both tasks an image can be represented as a RAG (Region Adjacency Graph), where image segments are represented as nodes and their adjacency is represented as edges which may contain information about e.g. the distances between adjacent segments. For both tasks graph-processing methods can be used, yielding promising results~\cite{monfardini2006graph}~\cite{bianchini2005recursive}~\cite{quek2011structural}.

Another classic example where structure of the data plays a crucial role in its understanding is the natural language processing. In the unconstrained case, the input data may consists of arbitrarily complex sentences. As a sentence can be transformed into a graph reflecting its syntax, a graph-processing model can be trained to parse such sentences. One of the first graph-processing models was already evaluated on such a task~\cite{pollack1990recursive} and more recent solutions are also present in the literature~\cite{costa2003towards}. 
