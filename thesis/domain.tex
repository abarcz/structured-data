
\chapter{Domains of application}
This chapter presents domains where data is organized into a structured form, that is form of sequences or graphs. The necessity of processing differently such kinds of data arose from the structure of the data itself. To present this difference we must first summarize what is the task of classification and regression in the most common sense in data processing domain. A common statistical classifier (which later on is called a \emph{vectorial} classifier) takes as input \emph{samples} from a given \emph{dataset}, representing real world objects, and associates each sample with a category. The samples are fixed-length vectors of numeric values. Each position in such a vector represents a feature of the sample, which is quantified by a real or integer value. The mapping from features to positions in the vector is fixed and must hold for each sample in the dataset. The category is represented by a non-empty fixed-length vector of integer values, where once again the position of each value is meaningful (we can say it's a \emph{positional} representation). For the regression task, a vector of real (or integer) values is associated with each sample instead of a category. The domain of vectorial classifiers is well developed and includes, among other solutions, neural networks, support vector machines, na√Øve Bayes classifiers and random forests.

In the case of graph processing, the nature of the data is different. Each \emph{sample} is represented by a graph. A \emph{dataset} may consist of a single or several graphs. Each graph consists of nodes, connected with edges. Each node can be described by its \emph{label}, a fixed-length vector of reals. Each edge can also be labelled, with a fixed-length vector of reals of different size. Edges can be directed or undirected. An example of a simple graph was presented in Fig.~\ref{fig:simple_tree}.

\begin{figure}
\begin{center}
	\includegraphics[scale=0.4]{img/tree}
	\caption{A simple binary tree}
	\label{fig:simple_tree}
\end{center}
\end{figure}

 If such a graph was to be used as input for a common classifier, it would be necessary to transform the structured representation into a plain vector. It could be accomplished in several ways, one of the most obvious would be to perform a preorder walk on the tree and list the node labels in the order they were visited. Such a walk would result in the representation $[A,B,D,E,C]$. It can be seen that the explicit information about node adjacency was lost. Instead, the information is provided implicitly, according to a coding which must be known a priori to properly interpret such a vector representation. That means that a model learning to classify such graph representations would have to learn the encoded relationship, instead of using it from the beginning to learn other, unknown and interesting relationships affecting the samples category. The resulting learning task becomes even harder if such sequential representations contain long-distance relationships. Different encodings from structured data to vectors exist, however, they all share that flaw.

Moreover, the inadequacy of simple vector representation becomes even more apparent when the graph structure becomes more complicated. First of all, if edge labels are present in the vector representation, the representation becomes a mix of data belonging to two different entities - nodes and edges. Once again the classifier doesn't know which part of the data corresponds to the first entity and which to the other. The same applies to directed and undirected edges. If two edges in a graph are connected by a directed edge, presumably one of the nodes in the relation has got a larger impact on the other than vice versa. On the contrary, an undirected or bidirectional edge edge implies an equal impact of both nodes on each other. What if a graph contains both types of edges? How should one type of edges be distinguished from the other one? Secondly, let's consider the case of cyclic dependencies. Even if a meaningful representation of the graph is built ignoring cycles, e.g. by constructing a minimum spanning tree, some explicit information about connections is lost. An example of such data are chemical compounds containing groups of atoms forming cyclic bonds. Another problem lies in the positional nature of vectorial data. If a representation is built by simply storing node labels one after another, this representation becomes vulnerable to any reordering of the children of a node. An additional effort must be made to assure a consistent ordering of the potentially difficult to order data, while the ordering of the children of a node may be irrelevant in the dataset considered.

It can be seen that in order to properly process structured data, a different approach must be used. The data should be processed in a way that exploits properly the information contained in its structure - by means of building a sufficient representation or by processing the structured data directly. Domains, where graph-oriented processing is already used include chemistry (QSAR, computer-aided drug design), pattern recognition and natural language processing.






