
\chapter{Graph processing models}
\noindent A model considered as fully capable of processing structured data, should be able to:
\begin{enumerate}
	\item build data representation
	\begin{enumerate}
		\item minimal
		\item exploiting sufficiently the structure of the data
		\item adequate for subsequent processing (classification, regression)
	\end{enumerate}
	\item perform classification / regression on the structured data
	\begin{enumerate}
		\item taking into consideration the structure encoded in the representation
		\item with a high generalization capacity
	\end{enumerate}
\end{enumerate}
These two main tasks are often intertwined with each other, as a classification procedure may affect the procedure of representation building and vice versa. It is also possible for a model to focus only on representation building, while leaving the task of processing to a common statistical classifier, such as a support vector machine. Two main families of models capable of processing structured data are the \emph{symbolic} and the \emph{connectionist} family. The first one originates in the artificial intelligence domain and focus on inferring relationships by means of inductive logic programming. The \emph{connectionist} models focus on modelling relationships with the use of interconnected networks of simple units. The different models originating from these two families are:
\begin{enumerate}
	\item inductive logic programming
	\item evolutionary algorithms
	\item probabilistic models: Bayes networks and Markov random fields
	\item graph kernels
	\item neural network models
\end{enumerate}
The main area of interest of this thesis are the connectionist models based on neural networks. The connectionist models make the fewest assumptions about the domain of the dataset and thus provide a potentially most general method for processing structured data.
